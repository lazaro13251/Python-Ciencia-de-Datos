# Introducción a Python para Ciencia de Datos

Bienvenidos a los cursos de capacitación de Ciencia de Datos diseñado por el equipo de Hiperautomatización e Inteligencia Artificial como parte del programa de Centros de Excelencia. Este curso es el primero en una serie de cursos desarrollados con la intención de dotar a los participantes de habilidades prácticas y teóricas fundamentales para la ciencia de datos, preparándolos para enfrentar desafíos reales en el ámbito profesional.

Este es el primero de cuatro cursos:

1. Introducción a Python para Ciencia de Datos
2. Fundamentos matemáticos para Ciencia de Datos
3. Python para análisis de datos
4. Introducción a Aprendizaje de Máquina

Para acceder a los siguientes cursos es necesario aprobar los anteriores.

## Forma de evaluación

- Cada sesión tiene una evaluación al finalizar los cuadernos que se tendrá que subir a un forms.
  - Dichas evaluaciones tendrán que ser subidas hasta antes del inicio de la siguiente sesión (por ejemplo, subir la sesión 1 antes de la sesión 2).
- Las evaluaciones por sesión y las asistencias (no es obligatoria, pero hay que justificarlo a través del chat privado en Teams) serán consideradas para acceder a la evaluación.
- Habrá una evaluación final que representa el 100% de la evaluación. Se tendrá que obtener un mínimo de 80% para obtener el certificado.
- En caso de no aprobar se podrá solicitar una evaluación extraordinaria que comprenderá el contenido del material.

Subir archivo de solución de evaluaciones tipo `.ipynb` con la siguiente convención de nombrado.

`{primer-nombre}_{primer-apellido}_{segundo-apellido}_evaluacion_S3.ipynb`

Por ejemplo:

`Fernando_Avitua_Varela_evaluacion_S3.ipynb`

A continuación, se muestra el temario que seguiremos en este curso.

<!--
Este curso de cuatro sesiones, de dos horas cada una, está estructurado para introducir a los profesionales de áreas técnica al lenguaje `Python`, abarcando desde la configuración del entorno de desarrollo hasta conceptos introductorios de análisis de datos y visualización.

Iniciaremos con la exploración de herramientas críticas como Colab, Jupyter y VSCode, seguido de una detallada revisión de la instalación de `Python` en diversas plataformas. Después revisaremos las buenas prácticas del entorno de programación como definir un ambiente virtual específicando los diferentes requerimientos.

El curso profundiza en los fundamentos de `Python`, incluyendo tipos de datos, estructuras de control de flujo y manipulación de archivos, esenciales para el desarrollo en ciencia de datos.

Progresaremos hacia la aplicación práctica de librerías clave en el análisis de datos: Numpy para operaciones numéricas y Pandas para la gestión de dataframes, culminando con técnicas de visualización de datos mediante Matplotlib. Este enfoque equilibra teoría y práctica, permitiendo a los participantes aplicar inmediatamente los conocimientos adquiridos. -->

<!-- ### Python para análisis de datos

Este curso tiene como requerimiento el curso de `Introducción a Python` o que el participante cuente con fundamentos de programación en Python previos. En este curso se verán las herramientas necesarias para hacer una análisis descriptivo básico de datos. En este análisis se descubrirá información de datos que podrán tener mucho valor para el negocio por si mismo.

Se comenzará explorando más a detalle todas las funcionalidades de Pandas. Se verá como:
- Seleccionar subconjuntos de registros y columnas para analizarlos a detalle.
- Hacer manipulaciones útiles para tener las tablas en mejor formato.
- Realizar agregaciones en términos de promedios y otras estadísticas.
- Unir tablas para obtener información detallada de cada registro.
- Definir tipos de variables en pandas.
    - Aprender a manipular cantidades de fechas.
    - Manipulación de datos categóricos y de texto.

Después, ya con las herramientas necesarias para realizar la manipulación de los dataframes comenzaremos a analizar una base de datos **relevante para el negocio**

### Fundamentos matemáticos para Ciencia de Datos

Este programa está diseñado para ofrecer una comprensión profunda de los conceptos matemáticos y estadísticos esenciales que son piedras angulares en el campo de la ciencia de datos. A través de cuatro sesiones, abarcaremos desde los principios básicos de la probabilidad y la estadística hasta el álgebra lineal, la optimización, y más allá. Nuestro objetivo es brindarles las herramientas y el conocimiento necesarios para aplicar estos conceptos matemáticos en la resolución de problemas reales de ciencia de datos, mejorando así su capacidad analítica y su efectividad como científicos de datos.

#### Sesión 1: Probabilidad y Estadística Básica
En nuestra primera sesión, nos sumergiremos en el mundo de la probabilidad, explorando eventos aleatorios y su simulación usando herramientas como numpy y scipy.stats. Desarrollaremos una comprensión sólida de medidas estadísticas fundamentales como el promedio, la varianza, y la desviación estándar, e introduciremos los conceptos de distribuciones estadísticas clave, incluyendo la normal y la binomial. También aprenderemos a interpretar y crear histogramas, cuantiles, y boxplots, y discutiremos métodos para identificar outliers.

#### Sesión 2: Álgebra Lineal y Optimización
La segunda sesión se centrará en el álgebra lineal, una herramienta indispensable en el análisis de datos. Cubriremos la teoría y aplicación de matrices y vectores, productos y la solución de sistemas lineales. Además, introduciremos conceptos de optimización y exploraremos cómo encontrar rutas óptimas, un conocimiento crucial para la optimización de recursos en ciencia de datos.

#### Sesión 3: Distancias y Agrupamientos
Profundizaremos en el estudio de distancias y similitudes, fundamentales para el agrupamiento y la clasificación de datos. Aprenderemos sobre diferentes métricas de distancia y cómo estas se aplican para entender la similitud entre puntos de datos. También abordaremos las métricas de aglomeración y cómo pueden ser utilizadas para crear agrupamientos significativos dentro de los conjuntos de datos.

#### Sesión 4: Pruebas Estadísticas y Clasificación de Problemas de Ciencia de Datos
En nuestra sesión final, nos enfocaremos en pruebas estadísticas avanzadas, como la t-student y ANOVA, y cómo aplicarlas en pruebas A/B y en la correlación de variables. Exploraremos el tamaño de muestra efectivo y cómo determinarlo. Además, clasificaremos problemas de ciencia de datos en categorías como supervisados, no supervisados, y por refuerzo, y examinaremos métodos de regresión y clasificación, incluyendo regresión lineal simple y regresión logística, junto con métricas de evaluación como la precisión y el error cuadrático medio.

Cada sesión de este curso está diseñada para construir sobre los fundamentos previos, asegurando una comprensión integral y aplicable de los conceptos matemáticos en ciencia de datos. A través de ejercicios prácticos, ejemplos del mundo real, y la aplicación de software estadístico, este curso promete no solo mejorar su comprensión teórica, sino también su habilidad para aplicar estos conceptos en soluciones analíticas efectivas.

### Nivel técnico asociado

Este curso está diseñado para proporcionar una comprensión sólida y práctica de cómo aplicar técnicas de Machine Learning (ML) utilizando la biblioteca scikit-learn en Python, una de las herramientas más versátiles y utilizadas en la industria para el análisis de datos y la creación de modelos predictivos. A lo largo de las sesiones, exploraremos desde los fundamentos del ML hasta técnicas avanzadas de predicción, clasificación, y reducción de dimensionalidad, aplicando estos conceptos a casos de uso reales.

#### Sesión 1: Introducción al ML con scikit-learn
Iniciaremos con una visión general de Machine Learning y cómo scikit-learn facilita la implementación de estos modelos. Introduciremos los estimadores de scikit-learn, que son la base para la mayoría de las tareas de ML, y discutiremos cómo inicializar, entrenar, y evaluar un modelo básico. Además, cubriremos las métricas de desempeño de regresión más comunes, como el error cuadrático medio y el error absoluto medio, fundamentales para evaluar la precisión de nuestros modelos.

#### Sesión 2: Aprendizaje No Supervisado con scikit-learn
En esta sesión, nos enfocaremos en el aprendizaje no supervisado, explorando técnicas de reducción dimensional y selección de características, incluyendo el Análisis de Componentes Principales (PCA) y la Selección de Características Secuenciales (SFS). Además, abordaremos el clustering, con énfasis en el algoritmo de K-medias, aplicándolo a un caso de uso práctico relacionado con la competencia de clientes en el sector bancario.

#### Sesión 3: Predicciones y Pronósticos
Profundizaremos en la regresión lineal, discutiendo conceptos clave como el sobreajuste y subajuste, y cómo manejarlos mediante técnicas de entrenamiento, prueba, y validación. También introduciremos la validación cruzada, una técnica esencial para la evaluación de modelos en ML. Exploraremos el pronóstico de series de tiempo, utilizando herramientas como Prophet para casos de uso de detección de anomalías.

#### Sesión 4: Clasificación y Casos de Uso
La última sesión se centrará en la clasificación, una de las aplicaciones más importantes del ML. Discutiremos métricas de evaluación de modelos de clasificación como la precisión, exactitud, sensibilidad, puntaje F1 y la curva ROC. Aprenderemos a implementar la regresión logística y aplicarla en un caso de uso práctico para la detección de incumplimiento crediticio.

Este curso está diseñado no solo para proporcionar una base teórica sólida en ML, sino también para asegurar que los participantes puedan aplicar efectivamente estos conocimientos en situaciones reales, preparándolos para resolver desafíos complejos en el mundo de la ciencia de datos. Con una mezcla de teoría, práctica, y estudios de caso, los participantes estarán bien equipados para utilizar scikit-learn en sus proyectos de ML y avanzar en sus carreras como científicos de datos. -->

```{tableofcontents}

```

```{bibliography}

```
